{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ProteinWorkshop` Tutorial, Part 2 - Customizing an Existing Dataset\n",
    "![Datasets](../docs/source/_static/box_datasets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repurpose an existing dataset within the `ProteinWorkshop`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# %load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome back to the `ProteinWorkshop` tutorial series!\n",
    "\n",
    "To reuse existing data components available in the `ProteinWorkshop`, you can follow the following 5-step procedure:\n",
    "\n",
    "1. Use an existing dataset as either a pre-training or fine-tuning corpus, with or without full-atom context\n",
    "2. Load the requested dataset using the designed config\n",
    "3. Either pre-train or fine-tune a model using the selected dataset\n",
    "4. Reconfigure the selected dataset to use e.g., side-chain atom context\n",
    "5. Verify that e.g., side-chain torsions are now available as feature inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Use an existing dataset as either a pre-training or fine-tuning corpus, with or without full-atom context\n",
    "\n",
    "One can switch out the dataset for any other available option by replacing the value of `dataset` in `overrides`:\n",
    "\n",
    "`cfg = hydra.compose(\"template\", overrides=[\"encoder=schnet\", \"task=inverse_folding\", \"dataset=cath\", \"features=ca_angles\", \"+aux_task=none\"], return_hydra_config=True)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misc. tools\n",
    "import os\n",
    "\n",
    "# Hydra tools\n",
    "import hydra\n",
    "\n",
    "from hydra.compose import GlobalHydra\n",
    "from hydra.core.hydra_config import HydraConfig\n",
    "\n",
    "from proteinworkshop.constants import HYDRA_CONFIG_PATH\n",
    "from proteinworkshop.utils.notebook import init_hydra_singleton\n",
    "\n",
    "version_base = \"1.2\"  # Note: Need to update whenever Hydra is upgraded\n",
    "init_hydra_singleton(reload=True, version_base=version_base)\n",
    "\n",
    "path = HYDRA_CONFIG_PATH\n",
    "rel_path = os.path.relpath(path, start=\".\")\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(rel_path, version_base=version_base)\n",
    "\n",
    "cfg = hydra.compose(\n",
    "    config_name=\"train\",\n",
    "    overrides=[\n",
    "        \"encoder=schnet\",\n",
    "        \"task=inverse_folding\",\n",
    "        \"dataset=pdb\",\n",
    "        \"features=ca_angles\",\n",
    "        \"+aux_task=none\",\n",
    "    ],\n",
    "    return_hydra_config=True,\n",
    ")\n",
    "\n",
    "# Note: Customize as needed e.g., when running a sweep\n",
    "cfg.hydra.job.num = 0\n",
    "cfg.hydra.job.id = 0\n",
    "cfg.hydra.hydra_help.hydra_help = False\n",
    "cfg.hydra.runtime.output_dir = \"outputs\"\n",
    "\n",
    "HydraConfig.instance().set_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load the requested dataset using the designed config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinworkshop.configs import config\n",
    "\n",
    "cfg = config.validate_config(cfg)\n",
    "\n",
    "datamodule = hydra.utils.instantiate(cfg.dataset.datamodule)\n",
    "datamodule.setup(\"fit\")\n",
    "dl = datamodule.train_dataloader()\n",
    "\n",
    "for i in dl:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Either pre-train or fine-tune a model using the selected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinworkshop.finetune import finetune\n",
    "from proteinworkshop.train import train_model\n",
    "\n",
    "# train_model(cfg)  # Pre-train a model using the selected data\n",
    "# finetune(cfg)  # Fine-tune a model using the selected data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Reconfigure the selected dataset to use e.g., side-chain atom context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version_base = \"1.2\"  # Note: Need to update whenever Hydra is upgraded\n",
    "init_hydra_singleton(reload=True, version_base=version_base)\n",
    "\n",
    "path = HYDRA_CONFIG_PATH\n",
    "rel_path = os.path.relpath(path, start=\".\")\n",
    "\n",
    "GlobalHydra.instance().clear()\n",
    "hydra.initialize(rel_path, version_base=version_base)\n",
    "\n",
    "cfg = hydra.compose(\n",
    "    config_name=\"train\",\n",
    "    overrides=[\n",
    "        \"encoder=schnet\",\n",
    "        \"task=inverse_folding\",\n",
    "        \"dataset=cath\",\n",
    "        \"features=ca_sc\",\n",
    "        \"+aux_task=none\",\n",
    "    ],\n",
    "    return_hydra_config=True,\n",
    ")\n",
    "\n",
    "# Note: Customize as needed e.g., when running a sweep\n",
    "cfg.hydra.job.num = 0\n",
    "cfg.hydra.job.id = 0\n",
    "cfg.hydra.hydra_help.hydra_help = False\n",
    "cfg.hydra.runtime.output_dir = \"outputs\"\n",
    "\n",
    "HydraConfig.instance().set_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Verify that e.g., side-chain torsions are now available as feature inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteinworkshop.configs import config\n",
    "\n",
    "cfg = config.validate_config(cfg)\n",
    "\n",
    "datamodule = hydra.utils.instantiate(cfg)\n",
    "datamodule.setup(\"fit\")\n",
    "dl = datamodule.train_dataloader()\n",
    "\n",
    "for i in dl:\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Wrapping up\n",
    "\n",
    "Have any additional questions about using the existing data components provided in the `ProteinWorkshop`? [Create a new issue](https://github.com/a-r-j/ProteinWorkshop/issues/new/choose) on our [GitHub repository](https://github.com/a-r-j/ProteinWorkshop). We would be happy to work with you to leverage the full power of the repository!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
