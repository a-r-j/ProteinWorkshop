{
  "configs/dataset": [],
  "configs/features": [],
  "configs/framework_components/callbacks": [],
  "configs/framework_components/debug": [],
  "configs/framework_components/env": [],
  "configs/framework_components/extras": [],
  "configs/framework_components/hydra": [],
  "configs/framework_components/logger": [],
  "configs/metrics": [],
  "configs/ml_components/optimiser": [],
  "configs/ml_components/scheduler": [],
  "configs/ml_components/trainer": [],
  "configs/model": [],
  "configs/task": [],
  "configs/templates": [],
  "configs/transforms": [],
  "framework": [],
  "index": [],
  "installation": [],
  "ml_components": [],
  "modules/src.datasets": [],
  "modules/src.features": [],
  "modules/src.metrics": [],
  "modules/src.models": [
    {
      "source": "lr_scheduler_config = {\n    # REQUIRED: The scheduler instance\n    \"scheduler\": lr_scheduler,\n    # The unit of the scheduler's step size, could also be 'step'.\n    # 'epoch' updates the scheduler on epoch end whereas 'step'\n    # updates it after a optimizer update.\n    \"interval\": \"epoch\",\n    # How many epochs/steps should pass between calls to\n    # `scheduler.step()`. 1 corresponds to updating the learning\n    # rate after every epoch/step.\n    \"frequency\": 1,\n    # Metric to to monitor for schedulers like `ReduceLROnPlateau`\n    \"monitor\": \"val_loss\",\n    # If set to `True`, will enforce that the value specified 'monitor'\n    # is available when the scheduler is updated, thus stopping\n    # training if not found. If set to `False`, it will only produce a warning\n    \"strict\": True,\n    # If using the `LearningRateMonitor` callback to monitor the\n    # learning rate progress, this keyword can be used to specify\n    # a custom logged name\n    \"name\": None,\n}",
      "names": [],
      "example": {
        "document": "modules/src.models",
        "ref_id": "module-src.models.base",
        "headings": [
          "protein_workshop.models",
          "Base Classes"
        ]
      },
      "doc_lineno": 18
    }
  ],
  "modules/src.tasks": [],
  "modules/src.train": [],
  "modules/src.utils": [],
  "overview": [
    {
      "source": "from src.types import EncoderOutput\n\ndef forward(self, x: [Batch, ProteinBatch]) -> EncoderOutput:\n    node_emb = x.x\n    graph_emb = self.readout(node_emb, x.batch)\n    return EncoderOutput({\"node_embedding\": node_emb, \"graph_embedding\": graph_embedding})",
      "names": [],
      "example": {
        "document": "overview",
        "ref_id": "src-models-base-basemodel-and-src-models-base-benchmarkmodel-base-classes",
        "headings": [
          "Architectural Overview",
          "src.models.base.BaseModel and src.models.base.BenchMarkModel Base classes"
        ]
      },
      "doc_lineno": 70
    }
  ],
  "quickstart": [],
  "quickstart_component/downstream": [],
  "quickstart_component/pretrain": [],
  "tutorials": []
}