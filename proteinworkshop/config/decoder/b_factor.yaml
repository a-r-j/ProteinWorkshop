b_factor:
  _target_: "proteinworkshop.models.decoders.mlp_decoder.MLPDecoder"
  hidden_dim: [128, 128]
  dropout: 0.0 # dropout rate
  activations: ["relu", "relu", "none"]
  skip: "concat" # Or sum/False
  out_dim: 1
  input: "node_embedding"
