\section{ProteinWorkshop}
The overarching goal of \emph{ProteinWorkshop} is to effectively cover the design space of protein structure representation learning methods. To achieve this, the benchmark is highly modular by design, enabling evaluation of different combinations of structural encoders, protein featurisation schemes, and auxiliary tasks over a wide range of both supervised and unsupervised tasks.
A user manual is available in Appendix \ref{app:benchmark}, containing detailed listings and descriptions of all components.

\subsection{Featurisation Schemes}
Protein structures are typically represented as geometric graphs, with researchers opting to use a coarse-grained C$\alpha$ atoms graph as full atom representations can quickly become computationally intractable due to a large number of nodes. 
However, this is a lossy representation, with much of the structural detail, such as orientation of the backbone and sidechain structure, being only implicitly encoded.
Due to the computational burden incurred by operating on full-atom node representations, we focus primarily on C$\alpha$-based graph representations, investigating featurisation strategies to incorporate higher-level structural information. 
Note that we do provide utilities to enable users to work with backbone and full-atom graphs in the benchmark.
% We represent protein structures as geometric graphs, $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathbf{\vec{X}}, \mathbf{S}, \mathbf{\vec{V}})$, where $\mathcal{V}$ is a set of nodes, $\mathcal{E}$ is a set of edges, $\mathbf{\vec{X}} \in \mathbb{R}^{|\mathcal{V}| \times 3}$ is a matrix of Cartesian node coordinates, $\mathbf{S} \in \mathbb{R}^{|\mathcal{V}| \times d}$ is a matrix of $d$-dimension scalar node features, and $\mathbf{\vec{V}} \in \mathbb{R}^{|\mathcal{V}| \times d \times 3}$ is a tensor of vector-valued features. 
Details about different featurisation schemes are provided in Appendix \ref{app:featurisation} and Table \ref{tab:features}.

\subsection{Pre-training Tasks}

The benchmark contains a comprehensive suite of pretraining tasks. Broadly, these can be categorised into: masked-attribute prediction, denoising-based and contrastive learning-based tasks. These can be used as both a pretraining objective or as auxiliary tasks in a downstream supervised task.

\textbf{Sequence Denoising. } The benchmark contains two variations based on two sequence corruption processes $C(\tilde{\mathcal{S}} | \mathcal{S}, \nu)$ that receive an amino acid sequence $\mathcal{S} \in [0, 1]^{|\mathcal{V}| \times 23 }$ and return a sequence $\mathcal{S} \in [0, 1]^{|\mathcal{V}| \times 23 }$ with fraction $\nu$ of its positions corrupted. The first scheme is based on mutating a fraction of the residues to a random amino acid and tasking the model with recovering the uncorrupted sequence. The second is a masked residue prediction task, where a fraction of the residues are altered to a mask value and the model is tasked to recover the uncorrupted sequence.

\textbf{Structure Denoising. } We provide two structure-based denoising tasks: coordinate denoising and torsional denoising. In the coordinate denoising task, noise is sampled from a normal or uniform distribution and scaled by noise factor, $\nu \in \mathbb{R}$, and applied to each of the atom coordinates in the structure to ensure structural features, such as backbone or sidechain torsion angles, are also corrupted. The model is then tasked with predicting either the per-node noise or the original uncorrupted coordinates. For torsional denoising, the noise is applied to the backbone torsion angles and Cartesian coordinates are recomputed using pNeRF \citep{AlQuraishi2019} and the uncorrupted bond lengths and angles prior to feature computation. Similarly to the coordinate denoising task, the model is then tasked with predicting either the per-residue angular noise or the original dihedral angles.

\textbf{Sequence-Structure Co-Denoising. } This is a multitask formulation of the previously described structure and sequence denoising tasks, with separate output heads for denoising each modality.

\textbf{Masked Attribute Prediction. } 
We use inverse folding (Section \ref{sec:inverse-folding}) as a pretraining task.
The benchmark additionally incorporates the distance, angle and dihedral angle masked-attribute prediction \citep{zhang2023protein} as well as a backbone dihedral angle prediction task.

\textbf{pLDDT Prediction. } Structure prediction models typically provide per-residue pLDDT (predicted Local Distance Difference Test) scores as local confidence measures which have been shown to correlate well with disordered regions \citep{wilson2022alphafold2}. We formulate a node-level regression task on predicted structures, somewhat analogous to structure quality assessment, where the model is tasked with predicting the scaled per-residue pLDDT $y \in [0, 1]$ values.

%%%

\subsection{Downstream Tasks}
We curate several structure-based and sequence-based datasets from the literature and existing benchmarks\footnote{To retain focus on \emph{protein} representation learning, we deliberately exclude commonly-used tasks based on protein-small molecule interactions as it is hard to disentangle the effect of the small molecule representation and the potential for bias \citep{Boyles2019}}, summarised in Table \ref{tab:datasets}. The tasks are selected to evaluate not only the \emph{global} structure representational power of each method, but also to evaluate the ability of each method to learn informative \emph{local} representations for residue-level prediction and annotation tasks.

The raw structures are, where possible and accounting for obsolescence, retrieved directly from the PDB (or another structural source) as several processed datasets used by the community discard full atomic coordinates in favour of retaining only $C_\alpha$ positions, making them unsuitable for in-depth experimentation. 
This provides an entry point for users to apply a custom sequence of pre-processing steps, such as deprotonation or fixing missing regions which are common in experimental data.

\begin{table*}[!t]
    \centering
    \caption{\textbf{Overview of supervised tasks and datasets.}}
    \begin{adjustbox}{max width=\linewidth}
        \begin{tabular}{llcccccc}
        \toprule
        & \textbf{Task} & \textbf{Dataset Origin} & \textbf{Structures} &  \textbf{\# Train} & \textbf{\# Validation} & \textbf{\# Test} & \textbf{Metric} \\
        \midrule
        \multirow{4}{*}{\rotatebox[origin=c]{90}{Node-level}} &
        Inverse Folding & \citet{NEURIPS2019_f3a4ff48} & Experimental
        &
        3.9 M
        &
        105 K
        & 
        180 K & Perplexity
        \\
        & PPI Site Prediction & \citet{gainza2020deciphering} & Experimental 
        &
        478 K
        & 
        53 K
        &
        117 K & AUPRC
        \\
        & Metal Binding Site Prediction & & Experimental
        &
        1.1 M
        &
        13.7 K
        &
        29.8 K & Accuracy
        \\
        & Post-Trans. Mod. Site Prediction &
        \citet{Yan2023} & Predicted 
        
        &
        44 K
        &
        2.4 K
        &
        2.5 K & ROC-AUC \\
        \midrule
        \multirow{4}{*}{\rotatebox[origin=c]{90}{Graph-level}}
        & Fold Prediction & \citet{hou2017} & Experimental 
        &
        12.3 K
        &
        0.7 K
        &
        1.3/0.7/1.3 K & Accuracy
        \\
        & Gene Ontology Prediction & \citet{Gligorijevi2021} & Experimental 
        &
        27.5 K
        &
        3.1 K
        &
        3.0 K & F$_{\text{max}}$
        \\
        & Reaction Class Prediction & \citet{hermosilla2020intrinsic} &  Experimental 
        &
        29.2 K
        &
        2.6 K
        &
        5.6 K & Accuracy
        \\
        & Antibody Dev. Prediction & \citet{NEURIPSDATASETSANDBENCHMARKS2021_4c56ff4c} & Experimental 
        &
        1.7 K
        &
        0.24 K
        &
        0.48 K & AUPRC
        \\
        \bottomrule
        \end{tabular}
    \end{adjustbox}
    \label{tab:datasets}
\end{table*}

%%%

\subsubsection{Node-level Tasks}

\textbf{Inverse Folding. }
\label{sec:inverse-folding} 
Many generative methods for protein design produce backbone structures that require the design of an associated sequence. As a result, inverse folding is an important part of \emph{de novo} design pipelines for proteins \citep{Dauparas2022}.
% This task is a common protein engineering task where the goal is to recover an amino acid sequence given a structure up to backbone completeness. 
Formally, this is a node-level classification task where the model learns a mapping for each residue $r_i$ to an amino acid type $y \in \{1, \dots, n \}$, where $n$ is the vocabulary size ($n=20$ for the canonical set of amino acids).
Inverse folding is a generic task that can be applied to any dataset in the benchmark. In the literature, it is commonly evaluated on the CATH dataset (Section \ref{sec:pre-train-data}) compiled by \citet{NEURIPS2019_f3a4ff48}.

\textbf{PPI Site Prediction. } 
Identifying protein-protein interaction sites has important applications in developing refined protein-protein interaction networks and docking tools, providing biological context to guide protein engineering and target identification in drug discovery campaigns \citep{Jamasb2021}.
This task is a node-level binary classification task where the goal is to predict whether or not a residue is involved in a protein-protein interaction interface.
We use the dataset of experimental structures curated from the PDB by \citet{gainza2020deciphering} and retain the original splits, though we modify the labelling scheme to be based on inter-atomic proximity (3.5 \AA), which can be user-defined, rather than solvent exclusion. The dataset is curated from the PDB by preprocessing such as the presence of one of the seven specified ligands (e.g., ADP or FAD), clustering based on 30\% sequence identity and random subsampling. It contains 1,459 structures, which are randomly assigned to training (72\%), validation (8\%) and test set (20\%). 12 (\AA) radius patches were extracted from the generated structures and a patch labelled as part of a binding pocket if its centre point was < 3 (\AA) away from an atom of the corresponding ligand.

\textbf{Metal Binding Site Prediction. } 
Many proteins coordinate transition metal ions to carry out their functions. Predicting the binding sites of metal ions can elucidate the role of metal binding on protein function.
This is a binary node classification task where each residue is mapped to a label $y \in \{0, 1\}$ indicating whether the residue (or its constituent atoms) is within 3.5 (\AA) of a user-defined metal ion or ligand heteroatom, respectively.
We provide tooling to curate a dataset of experimental structures from the PDB for this task, where binding site assignments for each residue are computed on-the-fly. While the benchmark supports this task on arbitrary subsets of the PDB and ligands, we provide the Zinc-binding dataset from \citet{Drr2023} specifically for this task. The dataset is constructed by sequence-based clustering of the PDB at 30\% sequence identity to remove sequence and structural redundancy. Clusters with a member shorter than 3000 residues, containing at least one zinc atom with resolution better than 2.5 (\AA) determined by x-ray crystallography and not containing nucleic acids are used to compose the dataset. If multiple structures fulfil these criteria, the highest resolution structure is used. The train (2,085) / validation (26) / test (59) splits are constructed such that proteins in the validation and test sets have no partial overlap with any protein in the training data.


\textbf{Post-Translational Modification Site Prediction. } 
Identifying the precise sites where post-translational modifications (PTMs) occur is essential for understanding protein behaviour and designing targeted therapeutic interventions.
We frame prediction of PTM sites as a multilabel classification task where each residue is mapped to a label $y \in \{1, \dots, 13\}$ distinguishing between modifications on different amino acids (e.g. phosphorylation on S/T/Y and N-linked glycosylation on N).
We use a dataset of 48,811 AlphaFold2-predicted structures curated by \citet{Yan2023}, where each structure contains the PTM metadata necessary to construct residue-wise site prediction labels. The dataset is split into training (43,907, validation (2,393) and test (2,511) sets based on 50\% sequence identity and 80\% coverage.

\subsubsection{Graph-level Tasks}

\textbf{Fold Prediction. }
The utility of this task is that it serves as a litmus test for the ability of a model to distinguish different structural folds. It stands to reason that models that perform poorly on distinguishing fold classes likely learn limited or low-quality structural representations.
This is a multiclass graph classification task where each protein, $\mathcal{G}$, is mapped to a label $y \in \{1, \dots, 1195\}$ denoting the fold class.
We adopt the fold classification dataset originally curated from SCOP 1.75 by \citep{hou2017}. This provides three different test sets stratified based on topological similarity: Fold, in which proteins originating from the same superfamily are absent during training; Superfamily, in which proteins originating from the same family are absent during training; and Family, in which proteins from the same family are present during training.

\textbf{Gene Ontology Prediction. }
Predicting protein function in the form of functional annotations such as GO terms has important applications in protein analysis and engineering, providing researchers with the ability to cluster functionally-related structures or to guide protein generation methods to design new proteins with desired functional properties.
This is a multilabel classification task, assigning functional Gene Ontology (GO) annotation to structures. GO annotations are assigned within three ontologies: biological process (BP), cellular component (CC) and molecular function (MF). We use the dataset of experimental structures curated from the PDB by \citet{Gligorijevi2021} and retain the original multi-cutoff based splits, with cutoff at 95\% sequence similarity. 

\textbf{Reaction Class Prediction. } 
As proteins' reaction classifications are based on their enzyme-catalyzed reaction according to all four levels of the standard Enzyme Commission (EC) number, methods that predict such classifications may help elucidate the function of newly-designed proteins as they are developed.
This is a multiclass graph classification task where each protein, $\mathcal{G}$, is mapped to a label $y \in {\{1, ..., 384\}}$ denoting which class of reactions a given protein catalyzes; all four levels of the EC assignment are employed to define the reaction class label.
We adopt the reaction class prediction dataset originally curated from the PDB by \citet{hermosilla2020intrinsic}, split on the basis of sequence similarity using a 50\% threshold.

\textbf{Antibody Developability Prediction. }
Therapeutic antibodies must be optimised for favourable physicochemical properties in addition to target binding affinity and specificity to be viable development candidates. Consequently, we frame prediction of antibody developability as a binary graph classification task indicating whether a given antibody is developable.We adopt the antibody developability dataset originally curated from SabDab \citep{dunbar2014sabdab} by \citet{Chen2020}.
This dataset contains 2,426 antibodies that have both sequences and PDB structures available, where each example contains both a heavy chain and a light chain with resolution < 3 (\AA). 
The label is based on thresholding the developability index (DI) \citep{Lauer2012} 
as computed by BIOVIA's platform \citep{Accelrys2018BioviaDiscoveryStudio}, which relies on an antibody's hydrophobic and electrostatic interactions.
This task is interesting from a benchmarking perspective as it enables targeted performance assessment of models on a specific (immunoglobulin) fold, providing insight into whether general-purpose structure-based encoders can be applicable to fold-specific tasks.

\subsection{Pre-training Datasets}\label{sec:pre-train-data}

The benchmark contains several large corpora of both experimental and predicted structures that can be used for pretraining or inference. We provide utilities for configuring supervised tasks and splits directly from the PDB.
Additionally, we build storage-efficient dataloaders for large pretraining corpora of predicted structures (AlphaFoldDB, ESM Atlas).
We believe our codebase will considerably reduce the barrier to entry for working with large structure-based datasets. 
% Additionally, we provide ready-to-go dataloaders for several large-scale collections of predicted structures derived from both AlphaFold2 \citep{jumper2021highly} and ESMFold \citep{lin2022language}. 
% This is facilitated by FoldComp \citep{Kim2023}, a (minimally) lossy compression scheme for predicted protein structures. FoldComp stores protein structures as a collection of discretised dihedral and bond angles which can be used to reconstruct the whole structure using fixed bond lengths and canonical amino acid geometry. FoldComp achieves a disk-space reduction of almost an order of magnitude, describing a residue with only 13 bytes -- down from 97 bytes per-residue in a traditional uncompressed format. Whilst lossy, this procedure results in 0.08 \AA\ and 0.14 \AA\ RMSD for backbone and all-atom reconstruction, making it highly suitable for pretraining tasks which use input representations complete up to the backbone. Furthermore, this lightweight format enables the dataloaders in the benchmark to read structures \emph{directly from disk} with no pre-processing or caching required.

\subsubsection{Experimental Structures}

\textbf{PDB. } We provide utilities for curating datasets directly from the Protein Data Bank \citep{Berman2000}. In addition to using the collection in its entirety, users can define filters to subset and split the data using a combination of structural similarity, sequence similarity or temporal strategies. Structures can be filtered by length, number of chains, resolution, deposition date, presence/absence of particular ligands and structure determination method. 
% The benchmark supports working with PDB structures in both \texttt{.pdb} and \texttt{.mmtf} format \citep{Bradley2017}, which significantly reduces the requirements for data storage.

\textbf{CATH. } We provide the dataset derived from CATH 4.2 40\% \citep{Knudsen2010} non-redundant chains developed by \citet{NEURIPS2019_f3a4ff48} as an additional, smaller, pretraining dataset. 
% These data are split based on random assignment of the CATH topology classifications based on an 80/10/10 split.

\textbf{ASTRAL. } ASTRAL \citep{Brenner2000} provides protein \emph{domain} structures which are regions of proteins that can maintain their structure and function independently of the rest of the protein. Domains typically exhibit highly-specific functions and can be considered structural building blocks.

\subsubsection{Predicted Structures}

\textbf{AlphaFoldDB Representative Structures.} This dataset contains 2.27 million representative structures, identified through large-scale structural-similarity-based clustering of the 214 million structures contained in the AlphaFold Database \citep{Varadi2021} using FoldSeek \citep{vanKempen2023}. We additionally provide a subset of this collection --- the so-called dark proteome --- corresponding to the 31\% of the representative structures that lack annotations.

\textbf{ESM Atlas, ESM High Quality.} These datasets are compressed collections of predicted structures produced by ESMFold. ESM Atlas is the full collection of all 772m predicted structures for the MGnify 2023 release \citep{Richardson2022}. ESM High Quality is a curated subset of high confidence (mean pLDDT) structures from the collection.
