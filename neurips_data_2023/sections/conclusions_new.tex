\section{Conclusions}
% This work focuses on building a comprehensive and multi-task benchmark for protein structure representation learning. Key findings include that structural pre-training, as well as auxiliary sequence tasks, improve performance on a wide range of tasks and that incorporating more structural detail in the featurisation improves downstream performance. Our benchmark is flexible for including new tasks and datasets and is open to the wider research community. For future work, we aim to include several of the remaining tasks in our benchmark as an additional set of experiments, to further expand the scope of our findings.

This work focuses on building a comprehensive and multi-task benchmark for protein structure representation learning. \emph{ProteinWorkshop} provides a unified implementation of large pretraining corpora, featurisation schemes, geometric GNN models and benchmarking tasks to evaluate the effectiveness of protein structure encoding methods.
Key findings include that structural pretraining, as well as auxiliary sequence denoising tasks, improve performance on a wide range of downstream tasks and that incorporating more structural detail in featurisation improves performance.
% \textbf{Future Work. }
% Importantly, we would like to advocate for rigorous and continuous re-evaluation of protein representation learning to stay up to date with new advances in protein structure prediction, such as modelling quaternary structures and molecular machines.
Our benchmark is flexible for including new tasks and datasets and is open to the wider research community.

% \textbf{Limitations.} Due to the large hardware requirements of our initial benchmarking experiments, currently we only evaluate methods using two representative structure-based tasks, fold classification (to evaluate methods' global protein representations) and inverse folding (to evaluate methods' local protein representations), whereas six other tasks are available in our proposed benchmark. To address this limitation, in the near future, we plan to add supplementary experiments covering more of such tasks in our benchmark results.

% \textbf{Availability. } The benchmark code is available under a permissive MIT License at \url{https://anonymous.4open.science/r/ProteinWorkshop-B8F5} and accompanying documentation, preprocessed datasets and pretrained model weights will be hosted publicly in the future. 
% Preprocessed datasets and pretrained model weights are deposited on Zenodo at the following URLs, respectively: \url{https://zenodo.org/record/8282470} and \url{https://zenodo.org/record/8287754}.

\section{Acknowledgements}
We acknowledge that this work was supported by a variety of institutions. ARJ was funded by a Biotechnology and Biological Sciences Research Council (BBSRC) DTP studentship (BB/M011194/1). AM and JC were supported by a U.S. NSF grant (DBI2308699) and two U.S. NIH grants (R01GM093123 and R01GM146340). CKJ was supported by the A*STAR Singapore National Science Scholarship (PhD). This work was performed using resources provided by the Cambridge Service for Data Driven Discovery (CSD3) operated by the University of Cambridge Research Computing Service (www.csd3.cam.ac.uk), provided by Dell EMC and Intel using Tier-2 funding from the Engineering and Physical Sciences Research Council (capital grant EP/T022159/1), and DiRAC funding from the Science and Technology Facilities Council (www.dirac.ac.uk). Additionally, this work was performed using high performance computing infrastructure provided by Research Support Services at the University of Missouri-Columbia (DOI: 10.32469/10355/97710).